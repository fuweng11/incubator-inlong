/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.inlong.agent.core.task;

import org.apache.commons.collections.CollectionUtils;
import org.apache.commons.lang3.StringUtils;
import org.apache.inlong.agent.common.AbstractDaemon;
import org.apache.inlong.agent.conf.AgentConfiguration;
import org.apache.inlong.agent.conf.JobProfile;
import org.apache.inlong.agent.core.AgentManager;
import org.apache.inlong.agent.core.job.JobManager;
import org.apache.inlong.agent.core.dbsync.PositionControl;
import org.apache.inlong.agent.db.JobProfileDb;
import org.apache.inlong.agent.message.BatchProxyMessage;
import org.apache.inlong.agent.mysql.protocol.position.LogPosition;
import org.apache.inlong.agent.utils.ThreadUtils;
import org.apache.inlong.common.monitor.LogCounter;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Map;
import java.util.Objects;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;

import static org.apache.inlong.agent.constant.AgentConstants.DBSYNC_UPDATE_POSITION_INTERVAL;
import static org.apache.inlong.agent.constant.AgentConstants.DEFAULT_UPDATE_POSITION_INTERVAL;
import static org.apache.inlong.agent.constant.CommonConstants.POSITION_SUFFIX;
import static org.apache.inlong.agent.constant.FetcherConstants.AGENT_HEARTBEAT_INTERVAL;
import static org.apache.inlong.agent.constant.FetcherConstants.DEFAULT_AGENT_FETCHER_INTERVAL;

/**
 * used to store task position to db, task position is stored as properties in JobProfile.
 * where key is task read file name and value is task sink position
 * note that this class is generated
 */
public class TaskPositionManager extends AbstractDaemon {

    private static final Logger LOGGER = LoggerFactory.getLogger(TaskPositionManager.class);
    private static volatile TaskPositionManager taskPositionManager = null;
    private final AgentManager agentManager;
    private final JobManager jobManager;
    private final JobProfileDb jobConfDb;
    private final AgentConfiguration conf;
    private final LogCounter logPrinter = new LogCounter(10, 100000, 60 * 1000);
    private final int updateZkInterval;
    // TODO: improve, merge two ack-position
    private final ConcurrentHashMap<String, ConcurrentHashMap<String, Long>> jobTaskPositionMap;
    private final ConcurrentHashMap<String, PositionControl> dbsyncJobPositions; // key:jobName
    private final LinkedBlockingQueue<BatchProxyMessage> logMapQueue; // dbsync-ack

    private TaskPositionManager(AgentManager agentManager) {
        this.conf = AgentConfiguration.getAgentConf();
        this.agentManager = agentManager;
        this.jobManager = agentManager.getJobManager();
        this.jobConfDb = agentManager.getJobManager().getJobConfDb();
        this.jobTaskPositionMap = new ConcurrentHashMap<>();
        this.logMapQueue = new LinkedBlockingQueue<>();
        this.dbsyncJobPositions = new ConcurrentHashMap<>();
        this.updateZkInterval = conf.getInt(DBSYNC_UPDATE_POSITION_INTERVAL, DEFAULT_UPDATE_POSITION_INTERVAL);
    }

    /**
     * task position manager singleton, can only generated by agent manager
     */
    public static TaskPositionManager getInstance(AgentManager agentManager) {
        if (taskPositionManager == null) {
            synchronized (TaskPositionManager.class) {
                if (taskPositionManager == null) {
                    taskPositionManager = new TaskPositionManager(agentManager);
                }
            }
        }
        return taskPositionManager;
    }

    /**
     * get taskPositionManager singleton
     */
    public static TaskPositionManager getInstance() {
        if (taskPositionManager == null) {
            throw new RuntimeException("task position manager has not been initialized by agentManager");
        }
        return taskPositionManager;
    }

    @Override
    public void start() throws Exception {
        submitWorker(taskPositionFlushThread());
        if (conf.enableHA()) {
            submitWorker(dbSyncAckWaitDataThread());
            submitWorker(dbSyncPositionUpdateThread());
        }
    }

    public void addRunningJobPos(String jobName, PositionControl positionControl) {
        PositionControl posControl = dbsyncJobPositions.put(jobName, positionControl);
        if (posControl != null) {
            LOGGER.info("job {} has been in runningJobPosMap, update it", jobName);
        }
    }

    public void removeRunningJobPos(String jobName) {
        dbsyncJobPositions.remove(jobName);
    }

    private Runnable dbSyncAckWaitDataThread() {
        return () -> {
            while (isRunnable() || logMapQueue.size() > 0) {
                try {
                    BatchProxyMessage wAckPkgData = null;
                    int delCnt = 0;
                    do {
                        try {
                            wAckPkgData = logMapQueue.poll(1, TimeUnit.SECONDS);
                        } catch (InterruptedException ei) {
                            LOGGER.error("log map queue poll error", ei);
                        }
                        handleAckPosition(wAckPkgData);
                        // TODO: improve this flow control
                        if (wAckPkgData != null) {
                            if (delCnt > 10000) {
                                break;
                            } else {
                                delCnt++;
                            }
                        } else {
                            break;
                        }
                    } while (true);

                } catch (Throwable e) {
                    LOGGER.error("TaskPositionManager has exception ", e);
                }

            }

        };
    }

    private Runnable dbSyncPositionUpdateThread() {
        return () -> {
            while (isRunnable()) {
                try {
                    /*
                     * When there is no table name or field name matching rule, it needs to be updated with the position
                     * parsed by binlog
                     */
                    for (Map.Entry<String, PositionControl> runningJobPos : dbsyncJobPositions.entrySet()) {
                        String jobName = runningJobPos.getKey();
                        PositionControl posControl = runningJobPos.getValue();
                        if (posControl == null) {
                            LOGGER.warn("runningJob posControl [{}] is null!", jobName);
                            continue;
                        }
                        if (!posControl.isReaderRunning()) {
                            LOGGER.warn("runningJob [{}] is not running!", jobName);
                            continue;
                        }
                        LogPosition storePos = posControl.getStorePosition();
                        if (storePos == null) {
                            LOGGER.warn("runningJob [{}] store position is null", jobName);
                            continue;
                        }
                        LogPosition lastStorePosition = posControl.getLastStorePosition();
                        if (lastStorePosition != null && lastStorePosition.equals(storePos)) {
                            if (LOGGER.isDebugEnabled()) {
                                LOGGER.debug("position has stored, jobName = {} ,position = {}", jobName,
                                        lastStorePosition);
                            }
                            continue;
                        }
                        posControl.updateSenderPosition(storePos);
                    }
                    TimeUnit.SECONDS.sleep(updateZkInterval);
                } catch (Throwable e) {
                    LOGGER.error("getPositionUpdateTask has exception ", e);
                }

            }
        };
    }

    private void handleAckPosition(BatchProxyMessage sentData) {
        if (sentData == null) {
            return;
        }
        if (StringUtils.isBlank(sentData.getJobId()) || CollectionUtils.isEmpty(sentData.getPositions())) {
            if (LOGGER.isDebugEnabled()) {
                LOGGER.debug("ack dbsync sent data error, jobName or positions is empty");
            }
            return;
        }
        PositionControl jobPosControl = getJobPosControl(sentData.getJobId());
        if (jobPosControl != null) {
            jobPosControl.updateAckInfo(sentData);

        } else {
            if (LOGGER.isDebugEnabled()) {
                LOGGER.debug("ackJobSendPosition error, can't find running job = {} ", sentData.getJobId());
            }
        }
    }

    /**
     * Get the position control of job; backup job should be considered
     */
    private PositionControl getJobPosControl(String jobName) {
        PositionControl posControl = dbsyncJobPositions.get(jobName);
        if (posControl != null) {
            return posControl;
        }
        // may be switched, try to find the backup job
        posControl = dbsyncJobPositions.values().stream().filter(v -> {
            String bakJobName = v.getJobConf().getBakJobName();
            return Objects.equals(bakJobName, jobName);
        }).findFirst().orElse(null);
        if (posControl == null) {
            if (logPrinter.shouldPrint()) {
                LOGGER.error("can't find job {}, runningJobs {}", jobName, jobManager.getRunningJobs().keys());
            }
        } else {
            if (logPrinter.shouldPrint()) {
                LOGGER.warn("find backup job {} when getJob {}", posControl.getJobConf().getBakJobName(), jobName);
            }
        }

        return posControl;
    }

    private Runnable taskPositionFlushThread() {
        return () -> {
            while (isRunnable()) {
                try {
                    // check pending jobs and try to submit again.
                    for (String jobId : jobTaskPositionMap.keySet()) {
                        JobProfile jobProfile = jobConfDb.getJobById(jobId);
                        if (jobProfile == null) {
                            LOGGER.warn("jobProfile {} cannot be found in db, "
                                    + "might be deleted by standalone mode, now delete job position in memory", jobId);
                            deleteJobPosition(jobId);
                            continue;
                        }
                        flushJobProfile(jobId, jobProfile);
                    }
                    int flushTime = conf.getInt(AGENT_HEARTBEAT_INTERVAL,
                            DEFAULT_AGENT_FETCHER_INTERVAL);
                    TimeUnit.SECONDS.sleep(flushTime);
                } catch (Throwable ex) {
                    LOGGER.error("error caught", ex);
                    ThreadUtils.threadThrowableHandler(Thread.currentThread(), ex);
                }
            }
        };
    }

    private void flushJobProfile(String jobId, JobProfile jobProfile) {
        jobTaskPositionMap.get(jobId).forEach(
                (fileName, position) -> jobProfile.setLong(fileName + POSITION_SUFFIX, position));
        if (jobConfDb.checkJobfinished(jobProfile)) {
            LOGGER.info("Cannot update job profile {}, delete memory job in jobTaskPosition", jobId);
            deleteJobPosition(jobId);
        } else {
            jobConfDb.updateJobProfile(jobProfile);
        }
    }

    private void deleteJobPosition(String jobId) {
        jobTaskPositionMap.remove(jobId);
    }

    @Override
    public void stop() throws Exception {
        waitForTerminate();
    }

    /**
     * update job sink position
     *
     * @param size add this size to beforePosition
     */
    public void updateSinkPosition(BatchProxyMessage batchMsg, String sourcePath, long size) {
        if (conf.enableHA()) {
            logMapQueue.add(batchMsg);
            return;
        }
        ConcurrentHashMap<String, Long> positionTemp = new ConcurrentHashMap<>();
        ConcurrentHashMap<String, Long> position = jobTaskPositionMap.putIfAbsent(batchMsg.getJobId(), positionTemp);
        if (position == null) {
            JobProfile jobProfile = jobConfDb.getJobById(batchMsg.getJobId());
            positionTemp.put(sourcePath, jobProfile.getLong(sourcePath + POSITION_SUFFIX, 0));
            position = positionTemp;
        }
        Long beforePosition = position.getOrDefault(sourcePath, 0L);
        position.put(sourcePath, beforePosition + size);
    }

    public ConcurrentHashMap<String, Long> getTaskPositionMap(String jobId) {
        return jobTaskPositionMap.get(jobId);
    }

    public ConcurrentHashMap<String, ConcurrentHashMap<String, Long>> getJobTaskPosition() {
        return jobTaskPositionMap;
    }
}
