/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.inlong.agent.core.task;

import org.apache.commons.lang3.tuple.Pair;
import org.apache.inlong.agent.common.AbstractDaemon;
import org.apache.inlong.agent.conf.AgentConfiguration;
import org.apache.inlong.agent.conf.JobProfile;
import org.apache.inlong.agent.core.AgentManager;
import org.apache.inlong.agent.core.job.DBSyncJob;
import org.apache.inlong.agent.core.job.JobManager;
import org.apache.inlong.agent.db.JobProfileDb;
import org.apache.inlong.agent.entites.WaitAckDataInfo;
import org.apache.inlong.agent.message.BatchProxyMessage;
import org.apache.inlong.agent.mysql.protocol.position.LogPosition;
import org.apache.inlong.agent.utils.ThreadUtils;
import org.apache.inlong.common.monitor.LogCounter;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;
import java.util.Objects;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;

import static org.apache.inlong.agent.constant.CommonConstants.POSITION_SUFFIX;
import static org.apache.inlong.agent.constant.FetcherConstants.AGENT_HEARTBEAT_INTERVAL;
import static org.apache.inlong.agent.constant.FetcherConstants.DEFAULT_AGENT_FETCHER_INTERVAL;

/**
 * used to store task position to db, task position is stored as properties in JobProfile.
 * where key is task read file name and value is task sink position
 * note that this class is generated
 */
public class TaskPositionManager extends AbstractDaemon {

    private static final Logger LOGGER = LoggerFactory.getLogger(TaskPositionManager.class);
    private static volatile TaskPositionManager taskPositionManager = null;
    private final AgentManager agentManager;
    private final JobManager jobManager;
    private final JobProfileDb jobConfDb;
    private final AgentConfiguration conf;
    private final LinkedBlockingQueue<WaitAckDataInfo> logMapQueue;
    private final LogCounter logPrinter = new LogCounter(10, 100000, 60 * 1000);
    private ConcurrentHashMap<String, ConcurrentHashMap<String, Long>> jobTaskPositionMap;

    private TaskPositionManager(AgentManager agentManager) {
        this.conf = AgentConfiguration.getAgentConf();
        this.agentManager = agentManager;
        this.jobManager = agentManager.getJobManager();
        this.jobConfDb = agentManager.getJobManager().getJobConfDb();
        this.jobTaskPositionMap = new ConcurrentHashMap<>();
        this.logMapQueue = new LinkedBlockingQueue<>();
    }

    /**
     * task position manager singleton, can only generated by agent manager
     */
    public static TaskPositionManager getTaskPositionManager(AgentManager agentManager) {
        if (taskPositionManager == null) {
            synchronized (TaskPositionManager.class) {
                if (taskPositionManager == null) {
                    taskPositionManager = new TaskPositionManager(agentManager);
                }
            }
        }
        return taskPositionManager;
    }

    /**
     * get taskPositionManager singleton
     */
    public static TaskPositionManager getTaskPositionManager() {
        if (taskPositionManager == null) {
            throw new RuntimeException("task position manager has not been initialized by agentManager");
        }
        return taskPositionManager;
    }

    @Override
    public void start() throws Exception {
        submitWorker(taskPositionFlushThread());
        if (conf.enableHA()) {
            submitWorker(dbSyncAckWaitDataThread());
        }
    }

    private Runnable dbSyncAckWaitDataThread() {
        return () -> {
            while (isRunnable() || logMapQueue.size() > 0) {
                try {
                    WaitAckDataInfo wAckPkgData = null;
                    HashMap<String, ArrayList<Pair<LogPosition, Long>>> logMap;
                    int delCnt = 0;
                    do {
                        try {
                            wAckPkgData = logMapQueue.poll(1, TimeUnit.SECONDS);
                        } catch (InterruptedException ei) {
                            LOGGER.error("log map queue poll error", ei);
                        }
                        if (null != wAckPkgData && (logMap = wAckPkgData.getPositionMap()) != null) {
                            for (Map.Entry<String, ArrayList<Pair<LogPosition, Long>>> entry : logMap.entrySet()) {
                                ackJobSendPosition(entry.getKey(), entry.getValue());
                            }

                            HashMap<String, Integer> cntMap = wAckPkgData.getInstCntMap();
                            for (Map.Entry<String, Integer> entry : cntMap.entrySet()) {
                                DBSyncJob job = getJobFailover(entry.getKey());
                                if (job != null) {
                                    job.ackJobData(entry.getValue());
                                }
                            }
                        } else if (wAckPkgData != null) {
                            logMap = wAckPkgData.getPositionMap();
                            if (LOGGER.isDebugEnabled()) {
                                LOGGER.debug("logMap == {}", logMap == null ? "null" : logMap.size());
                            }
                        }

                        if (wAckPkgData != null) {
                            if (delCnt > 10000) {
                                break;
                            } else {
                                delCnt++;
                            }
                        } else {
                            break;
                        }
                    } while (true);

                } catch (Throwable e) {
                    LOGGER.error("TaskPositionManager has exception ", e);
                }

            }

        };
    }

    private void ackJobSendPosition(String jobName, ArrayList<Pair<LogPosition, Long>> positionsList) {
        if (positionsList != null && positionsList.size() > 0) {
            for (Pair<LogPosition, Long> pair : positionsList) {
                ackJobSendPosition(jobName, pair.getLeft());
            }
        }
    }

    private void ackJobSendPosition(String jobName, LogPosition ackPosition) {
        DBSyncJob job = jobManager.getRunningJobs().get(jobName);
        if (job != null) {
            job.ackSendPosition(ackPosition);
        } else {
            if (LOGGER.isDebugEnabled()) {
                LOGGER.debug("ackJobSendPosition jobName = {} position = {} ", jobName, ackPosition);
            }
        }
    }

    private DBSyncJob getJobFailover(String instName) {
        DBSyncJob job = jobManager.getRunningJobs().get(instName);
        if (job == null) {
            //may switched, try to find the backup job
            job = jobManager.getRunningJobs().values().stream().filter(v -> {
                String insName = v.getDBSyncJobConf().getBakMysqlIp() + ":"
                        + v.getDBSyncJobConf().getBakMysqlPort() + ":" + v.getDBSyncJobConf().getServerId();
                return Objects.equals(instName, insName);
            }).findFirst().orElse(null);
            if (job == null) {
                if (logPrinter.shouldPrint()) {
                    LOGGER.error("can't find job {}, runningJobs {}", instName, jobManager.getRunningJobs().keys());
                }
            } else {
                String insName = job.getDBSyncJobConf().getBakMysqlIp() + ":"
                        + job.getDBSyncJobConf().getBakMysqlPort();
                if (logPrinter.shouldPrint()) {
                    LOGGER.warn("find backup job {} when getJob {}",
                            insName, instName);
                }
            }
        }
        return job;
    }

    //TODO:use?
    public void addRecodeLogPosition(BatchProxyMessage pkgData) {
        logMapQueue.add(new WaitAckDataInfo(pkgData));
    }

    private Runnable taskPositionFlushThread() {
        return () -> {
            while (isRunnable()) {
                try {
                    // check pending jobs and try to submit again.
                    for (String jobId : jobTaskPositionMap.keySet()) {
                        JobProfile jobProfile = jobConfDb.getJobById(jobId);
                        if (jobProfile == null) {
                            LOGGER.warn("jobProfile {} cannot be found in db, "
                                    + "might be deleted by standalone mode, now delete job position in memory", jobId);
                            deleteJobPosition(jobId);
                            continue;
                        }
                        flushJobProfile(jobId, jobProfile);
                    }
                    int flushTime = conf.getInt(AGENT_HEARTBEAT_INTERVAL,
                            DEFAULT_AGENT_FETCHER_INTERVAL);
                    TimeUnit.SECONDS.sleep(flushTime);
                } catch (Throwable ex) {
                    LOGGER.error("error caught", ex);
                    ThreadUtils.threadThrowableHandler(Thread.currentThread(), ex);
                }
            }
        };
    }

    private void flushJobProfile(String jobId, JobProfile jobProfile) {
        jobTaskPositionMap.get(jobId).forEach(
                (fileName, position) -> jobProfile.setLong(fileName + POSITION_SUFFIX, position)
        );
        if (jobConfDb.checkJobfinished(jobProfile)) {
            LOGGER.info("Cannot update job profile {}, delete memory job in jobTaskPosition", jobId);
            deleteJobPosition(jobId);
        } else {
            jobConfDb.updateJobProfile(jobProfile);
        }
    }

    private void deleteJobPosition(String jobId) {
        jobTaskPositionMap.remove(jobId);
    }

    @Override
    public void stop() throws Exception {
        waitForTerminate();
    }

    /**
     * update job sink position
     *
     * @param size add this size to beforePosition
     */
    public void updateSinkPosition(String jobInstanceId, String sourcePath, long size) {
        ConcurrentHashMap<String, Long> positionTemp = new ConcurrentHashMap<>();
        ConcurrentHashMap<String, Long> position = jobTaskPositionMap.putIfAbsent(jobInstanceId, positionTemp);
        if (position == null) {
            JobProfile jobProfile = jobConfDb.getJobById(jobInstanceId);
            positionTemp.put(sourcePath, jobProfile.getLong(sourcePath + POSITION_SUFFIX, 0));
            position = positionTemp;
        }
        Long beforePosition = position.getOrDefault(sourcePath, 0L);
        position.put(sourcePath, beforePosition + size);
    }

    public ConcurrentHashMap<String, Long> getTaskPositionMap(String jobId) {
        return jobTaskPositionMap.get(jobId);
    }

    public ConcurrentHashMap<String, ConcurrentHashMap<String, Long>> getJobTaskPosition() {
        return jobTaskPositionMap;
    }
}
